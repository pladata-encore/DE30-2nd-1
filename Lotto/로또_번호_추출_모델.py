# -*- coding: utf-8 -*-
"""로또_번호_추출_모델.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s_ROkFsd8_DHfMr0KBbKYokbM-mpYq8M

# 라이브러리 정리
"""

import pandas as pd
import numpy as np
from torch.utils.data.dataset import Dataset
import torch.nn as nn
import torch
import tqdm
from torch.optim.adam import Adam
from torch.utils.data.dataloader import DataLoader
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import pickle

"""# 데이터셋 정리

## 학습에 필요한 컬럼만 선택 후 새로운 데이터 프레임 생성
"""

lotto_df = pd.read_csv('/content/로또번호.csv')
lotto_df.reset_index(drop=True, inplace=True)
lotto_df = lotto_df.drop(columns='Unnamed: 0')

"""## 학습 데이터 X, y 생성"""

X = []
y = []
data = lotto_df.values
window_size = 5
for i in range(len(data)-window_size):
  X.append(data[i : i + window_size ])
  y.append(data[i+window_size])
X = np.array(X)
y = np.array(y)

"""## 모델 학습에 필요한 하이퍼파라미터 정의"""

# 하이퍼 파라메터
input_size = X.shape[-1]
hidden_size = 64
num_layers = 5
output_size = input_size
epochs = 100
lr = 1e-4

"""## 모델 학습에 필요한 디바이스 정의"""

device = "cuda" if torch.cuda.is_available() else 'cpu'

"""## 데이터셋 클래스 정의"""

# 데이터셋
class LottoDataset(Dataset):
  def __init__(self):
    lotto_df = pd.read_csv('/content/로또번호.csv')
    self.data = lotto_df.values

  def __len__(self):
    return len(self.data) - 5 # 사용가능한 배치

  def __getitem__(self, index):
    data = self.data[index: index+5, 1:]
    label = self.data[index+5, 1:]
    return data, label

"""## 데이터셋 객체 및 데이터 로더 정의"""

lottodataset = LottoDataset()
data,label = next(iter(lottodataset))
loader = DataLoader(lottodataset, batch_size=32)
data, label =  next(iter(loader))

"""# RNN"""

class LOTTO_RNN(nn.Module):
  def __init__(self):
    super(LOTTO_RNN,self).__init__()
    # 시계열 특징 추출
    self.rnn = nn.RNN(input_size = input_size,hidden_size=hidden_size,
                      num_layers=num_layers, batch_first=True)
     # (batch_size, 5,6) --> (batch_size, 5,64)

    # MLP 층 정의(분류기)  5*64 = 320
    self.fc1 = nn.Linear(in_features=5*64,out_features=64)
    self.fc2 = nn.Linear(in_features=64,out_features=6)
    self.relu = nn.ReLU()

  def forward(self,x, h):
    x, hn = self.rnn(x,h)  # x 마지막 RNN 층의 은닉 상태, hn 모든 RNN 층의 은닉 상태
    x = torch.reshape(x, (x.shape[0],-1))  # mlp층에 사용하기 위해서 모양 변경

    x = self.fc1(x)
    x = self.relu(x)
    x = self.fc2(x)
    return x

  def predict(self):
    final_preds = torch.round(pred).type(torch.int)
    predict_RNN = final_preds.cpu().numpy()
    return predict_RNN

# 학습
device = "cuda" if torch.cuda.is_available() else 'cpu'
rnn_model = LOTTO_RNN().to(device)
optim = Adam(rnn_model.parameters(),lr=1e-4)

iterator = tqdm.tqdm(range(50))
for epoch in iterator:
  for data, label in loader:
    optim.zero_grad()
    # 초기 은닉상태  (은닉층개수, 배치크기, 출력차원) -->0
    h0 = torch.zeros(5,data.shape[0],64).to(device)
    # 모델 forward - 예측
    pred = rnn_model(data.type(torch.FloatTensor).to(device), h0)
    # 손실
    loss = nn.MSELoss()(pred,label.type(torch.FloatTensor).to(device) )
    # 역전파
    loss.backward()
    # 가중치 업데이트(최적화)
    optim.step()
    iterator.set_description(f"epoch{epoch+1} loss:{loss.item()}")

# 평가용 데이터 로더
loader = DataLoader(lottodataset, batch_size=1)
preds = []
total_loss = 0

# 평가 수행
with torch.no_grad():
    for data, label in loader:
        # 초기 은닉 상태 생성
        h0 = torch.zeros(5, data.shape[0], 64).to(device)
        pred = rnn_model(data.type(torch.FloatTensor).to(device), h0)

        # 예측 값 반올림 및 정수형 변환
        rounded_pred = torch.round(pred).type(torch.int)

        # 필요한 경우 numpy 배열로 변환
        preds.append(rounded_pred.cpu().numpy())

        # 손실 계산
        loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device))
        total_loss += loss / len(loader)

# 전체 손실 출력
print(f"Total Loss: {total_loss.item()}")

# 예시로 첫 번째 배치의 예측 값과 실제 값을 확인
data, label = next(iter(loader))
h0 = torch.zeros(5, data.shape[0], 64).to(device)
pred = rnn_model(data.type(torch.FloatTensor).to(device), h0)

# 예측 값 반올림 및 정수형 변환
final_preds = torch.round(pred).type(torch.int)
print("RNN:", final_preds.cpu().numpy())

predict_RNN = final_preds.cpu().numpy()
torch.save(rnn_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_RNN')
pickle.dump(rnn_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_RNN.pkl','wb'))

rnn_model.predict()

"""# Cluster"""

class LOTTO_CLUSTER:
    def __init__(self, n_clusters=5):
        self.n_clusters = n_clusters
        self.scaler = StandardScaler()
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        self.lotto_df = None
        self.cluster_centers = None

    def load_and_preprocess_data(self):
        """Load data from a DataFrame and scale it using StandardScaler."""
        self.lotto_df = lotto_df
        return self.scaler.fit_transform(lotto_df)

    def fit(self):
        """Fit the KMeans model and compute cluster centers."""
        lotto_scaled = self.load_and_preprocess_data()
        self.kmeans.fit(lotto_scaled)
        # Inverse transform the centers to get them back in the original scale
        centers = self.scaler.inverse_transform(self.kmeans.cluster_centers_)
        self.cluster_centers = pd.DataFrame(np.round(centers).astype(int), columns=lotto_df.columns)

    def get_cluster_centers(self):
        """Return the cluster centers if available."""
        if self.cluster_centers is None:
            raise ValueError("Cluster centers are not available. Please call fit() before getting centers.")
        return self.cluster_centers.iloc[:, :-1]  # Skip the last column which typically might be 'Cluster' if added

    def predict(self):
        # Retrieve and format the cluster centers as per the requested output
        cluster_centers = cluster_model.get_cluster_centers()
        cluster_array = cluster_centers.values.flatten()  # Flatten the DataFrame to a 1D array for display
        # Printing the outputs in the desired format
        return cluster_array.tolist()

# Create and fit the model
cluster_model = LOTTO_CLUSTER(n_clusters=1)
cluster_model.fit()


# Retrieve and format the cluster centers as per the requested output
cluster_centers = cluster_model.get_cluster_centers()
cluster_array = cluster_centers.values.flatten()  # Flatten the DataFrame to a 1D array for display

# Printing the outputs in the desired format
print(f"CLUSTER: {cluster_array.tolist()}")

CLUSTER = cluster_array.tolist()
# torch.save(cluster_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_CLUSTER')
pickle.dump(cluster_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_CLUSTER.pkl','wb'))

"""# Cluster + PCA"""

# class LOTTO_PCA:
#     def __init__(self, n_clusters=5, n_components=2):
#         """PCA와 클러스터링을 위한 초기 설정"""
#         self.n_clusters = n_clusters
#         self.n_components = n_components
#         self.scaler = StandardScaler()
#         self.pca = PCA(n_components=n_components)
#         self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)
#         self.lotto_numbers = None
#         self.cluster_centers = None

#     def load_and_preprocess_data(self):
#         """데이터를 로드하고 필요한 전처리 작업 수행"""
#         self.lotto_df = lotto_df
#         # 데이터 스케일링
#         return self.scaler.fit_transform(lotto_df)

#     def fit(self):
#         """PCA를 통한 차원 축소 및 K-평균 클러스터링 수행"""
#         lotto_scaled = self.load_and_preprocess_data()
#         # PCA 적용
#         pca_result = self.pca.fit_transform(lotto_scaled)
#         # K-평균 클러스터링 적용
#         self.kmeans.fit(pca_result)
#         # 클러스터 중심을 원래 차원으로 복구
#         centers_pca = self.scaler.inverse_transform(self.pca.inverse_transform(self.kmeans.cluster_centers_))
#         self.cluster_centers = pd.DataFrame(np.round(centers_pca).astype(int), columns=list(range(1, 7)))
#         self.cluster_centers['Cluster'] = range(len(self.cluster_centers))

#     def predict(self):
#         """모든 데이터에 대해 클러스터 레이블 예측"""
#         if self.lotto_numbers is None:
#             raise ValueError("데이터를 로드하거나 모델을 학습해야 합니다.")
#         lotto_scaled = self.scaler.transform(self.lotto_numbers)
#         pca_result = self.pca.transform(lotto_scaled)
#         labels = self.kmeans.predict(pca_result)
#         self.lotto_numbers['Cluster'] = labels
#         return self.lotto_numbers

#     def get_cluster_centers(self):
#         """학습된 클러스터 중심값을 반환"""
#         if self.cluster_centers is None:
#             raise ValueError("모델을 먼저 학습해야 합니다.")
#         return self.cluster_centers

#     def predict(self):


# # 클래스 사용 예시
# pca_model = LOTTO_PCA(n_clusters=5, n_components=2)
# pca_model.fit()
# print("PCA Cluster Centers (Predicted Patterns):")
# print(lotto_model.get_cluster_centers())


# PCA = lotto_model.get_cluster_centers()
# torch.save(pca_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_PCA')
# pickle.dump(pca_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_PCA.pkl','wb'))

class LOTTO_PCA:
    def __init__(self, n_clusters=5, n_components=2):
        self.n_clusters = n_clusters
        self.n_components = n_components
        self.scaler = StandardScaler()
        self.pca = PCA(n_components=n_components)
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        self.lotto_df = None
        self.cluster_centers = None

    def load_and_preprocess_data(self):
        self.lotto_df = lotto_df
        return self.scaler.fit_transform(lotto_df)

    def fit(self):
        lotto_scaled = self.load_and_preprocess_data()
        pca_result = self.pca.fit_transform(lotto_scaled)
        self.kmeans.fit(pca_result)
        centers_pca = self.scaler.inverse_transform(self.pca.inverse_transform(self.kmeans.cluster_centers_))
        # Ensure the number of DataFrame columns matches the actual data columns
        self.cluster_centers = pd.DataFrame(np.round(centers_pca).astype(int), columns=lotto_df.columns)
        self.cluster_centers['Cluster'] = range(1, 1 + self.kmeans.n_clusters)

    def predict(self):
        if self.lotto_df is None:
            raise ValueError("You must load and preprocess the data before prediction.")
        lotto_scaled = self.scaler.transform(self.lotto_df)
        pca_result = self.pca.transform(lotto_scaled)
        labels = self.kmeans.predict(pca_result)
        self.lotto_df['Cluster'] = labels
        return self.lotto_df

    def get_cluster_centers(self):
        if self.cluster_centers is None:
            raise ValueError("Cluster centers are not available. Please call fit() before getting centers.")
        return self.cluster_centers

    def predict(self):
      pca_model = LOTTO_PCA(n_clusters=1, n_components=2)
      pca_model.fit()

      cluster_centers = pca_model.get_cluster_centers()
      cluster_array = np.array(cluster_centers.iloc[:, :-1])  # Exclude the 'Cluster' column
      return cluster_array.tolist()

# Example usage of the class
pca_model = LOTTO_PCA(n_clusters=1, n_components=2)
pca_model.fit()

# Retrieve and format the cluster centers as per the requested output
cluster_centers = pca_model.get_cluster_centers()
cluster_array = np.array(cluster_centers.iloc[:, :-1])  # Exclude the 'Cluster' column

# Printing the outputs in the desired format
print(f"CLUSTER + PCA: {cluster_array.tolist()}")

PCA = pca_model.get_cluster_centers()
# torch.save(pca_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_PCA')
pickle.dump(pca_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_PCA.pkl','wb'))

"""# 다층 퍼셉트론 (MLP)"""

# 다층 퍼셉트론 모델 정의
class LOTTO_MLP(nn.Module):
    def __init__(self, input_size=6, hidden_size=64, output_size=6):
        super(LOTTO_MLP, self).__init__()
        # MLP 레이어 구성
        self.layer1 = nn.Linear(input_size * 5, hidden_size)
        self.layer2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = torch.flatten(x, start_dim=1)
        x = self.relu(self.layer1(x))
        return self.layer2(x)

    def predict(self):
        predicted_lotto_numbers = generate_lotto_numbers(mlp_model, initial_sequence, num_predictions=1)
        for idx, numbers in enumerate(predicted_lotto_numbers, 1):
            print(f"MLP : {numbers[0]}")
        return numbers[0]

# 학습 함수 정의
def train_mlp_model( batch_size=32, epochs=50, lr=1e-3):
    # 데이터 로드
    dataset = LottoDataset()
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # 모델 초기화 및 설정
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = LOTTO_MLP().to(device)
    criterion = nn.MSELoss()
    optimizer = Adam(model.parameters(), lr=lr)

    # 모델 학습
    for epoch in range(epochs):
        model.train()
        total_loss = 0
        for data, label in dataloader:
            data, label = data.float().to(device), label.float().to(device)

            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, label)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

    return model

# 로또 번호 생성 함수
def generate_lotto_numbers(model, initial_sequence, num_predictions=1):
    """주어진 시퀀스를 바탕으로 다음 로또 번호를 생성"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.eval()
    with torch.no_grad():
        generated_numbers = []
        current_sequence = torch.tensor(initial_sequence, dtype=torch.float32).unsqueeze(0).to(device)

        for _ in range(num_predictions):
            predicted = model(current_sequence)
            # 1 ~ 45 범위로 제한하여 정수 변환
            predicted_rounded = torch.clamp(torch.round(predicted), min=1, max=45).cpu().numpy().astype(int)
            generated_numbers.append(predicted_rounded)

            # 새로운 번호를 시퀀스에 추가하고 맨 앞의 번호 제거
            new_sequence = np.vstack([current_sequence.cpu().numpy()[0, 1:], predicted_rounded])
            current_sequence = torch.tensor(new_sequence, dtype=torch.float32).unsqueeze(0).to(device)

    return generated_numbers


# 모델 학습 및 새로운 로또 번호 생성
mlp_model = train_mlp_model()
initial_sequence = np.array([
    [3, 15, 21, 30, 33, 42],
    [7, 12, 25, 31, 35, 40],
    [5, 14, 18, 29, 32, 39],
    [9, 19, 22, 28, 37, 41],
    [4, 13, 20, 24, 26, 36]
])

predicted_lotto_numbers = generate_lotto_numbers(mlp_model, initial_sequence, num_predictions=1)
for idx, numbers in enumerate(predicted_lotto_numbers, 1):
    print(f"MLP : {numbers[0]}")


MLP = numbers[0]
# torch.save(pca_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_PCA')
pickle.dump(mlp_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_MLP.pkl','wb'))

"""# CNN"""

class LOTTO_CNN(nn.Module):
    def __init__(self, input_channels=1, num_rows=5, num_cols=6, output_size=6):
        super(LOTTO_CNN, self).__init__()
        # CNN 레이어 구성
        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=(2, 2), stride=(1, 1))
        self.conv2 = nn.Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))
        # Conv2d 출력 크기 계산
        conv1_size = (num_rows - 2 + 1, num_cols - 2 + 1)  # kernel_size = 2, stride = 1, no padding
        conv2_size = (conv1_size[0] - 2 + 1, conv1_size[1] - 2 + 1)  # Second layer same as first
        conv_output_size = 64 * conv2_size[0] * conv2_size[1]  # Num channels * height * width
        # 완전 연결층
        self.fc1 = nn.Linear(conv_output_size, 128)
        self.fc2 = nn.Linear(128, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.unsqueeze(1)  # (batch_size, 1, 5, 6)
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = torch.flatten(x, start_dim=1)
        x = self.relu(self.fc1(x))
        return self.fc2(x)

    def predict(self):
      predicted_lotto_numbers = generate_lotto_numbers(cnn_model, initial_sequence, num_predictions=1)
      for idx, numbers in enumerate(predicted_lotto_numbers, 1):
          print(f"CNN : {numbers[0]}")
      return numbers[0]

# 모델 학습 및 번호 생성 코드는 이전 설명을 참조하면서 연속된 실행으로 인해 발생한 오류도 확인합니다.


# 학습 함수 정의
def train_cnn_model(batch_size=32, epochs=50, lr=1e-3):
    # 데이터 로드
    dataset = LottoDataset()
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # 모델 초기화 및 설정
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    cnn_model = LOTTO_CNN().to(device)
    criterion = nn.MSELoss()
    optimizer = Adam(cnn_model.parameters(), lr=lr)

    # 모델 학습
    for epoch in range(epochs):
        cnn_model.train()
        total_loss = 0
        for data, label in dataloader:
            data, label = data.float().to(device), label.float().to(device)

            optimizer.zero_grad()
            output = cnn_model(data)
            loss = criterion(output, label)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(dataloader)
        print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")

    return cnn_model

# 로또 번호 생성 함수
def generate_lotto_numbers(cnn_model, initial_sequence, num_predictions=1):
    """주어진 시퀀스를 바탕으로 다음 로또 번호를 생성"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    cnn_model.eval()
    with torch.no_grad():
        generated_numbers = []
        current_sequence = torch.tensor(initial_sequence, dtype=torch.float32).unsqueeze(0).to(device)

        for _ in range(num_predictions):
            predicted = cnn_model(current_sequence)
            # 1 ~ 45 범위로 제한하여 정수 변환
            predicted_rounded = torch.clamp(torch.round(predicted), min=1, max=45).cpu().numpy().astype(int)
            generated_numbers.append(predicted_rounded)

            # 새로운 번호를 시퀀스에 추가하고 맨 앞의 번호 제거
            new_sequence = np.vstack([current_sequence.cpu().numpy()[0, 1:], predicted_rounded])
            current_sequence = torch.tensor(new_sequence, dtype=torch.float32).unsqueeze(0).to(device)

    return generated_numbers


# 모델 학습 및 새로운 로또 번호 생성
cnn_model = train_cnn_model()
initial_sequence = np.array([
    [3, 15, 21, 30, 33, 42],
    [7, 12, 25, 31, 35, 40],
    [5, 14, 18, 29, 32, 39],
    [9, 19, 22, 28, 37, 41],
    [4, 13, 20, 24, 26, 36]
])

predicted_lotto_numbers = generate_lotto_numbers(cnn_model, initial_sequence, num_predictions=1)
for idx, numbers in enumerate(predicted_lotto_numbers, 1):
    print(f"CNN : {numbers[0]}")

CNN = numbers[0]
# torch.save(pca_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_PCA')
pickle.dump(cnn_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_CNN.pkl','wb'))

"""# Transformer"""

# RNN 모델 정의
class LOTTO_RNN(nn.Module):
    def __init__(self, input_size=6, hidden_size=64, num_layers=2, output_size=6):
        super(LOTTO_RNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x, h):
        out, hn = self.rnn(x, h)
        out = out[:, -1, :]  # 시계열의 마지막 시점
        out = self.fc(out)
        return out
    def predict(self):
        # 예측용 로또 번호 생성 예시 (예측에 적합한 이전 데이터 필요)
        initial_sequence = torch.tensor([[3, 15, 21, 30, 33, 42], [4, 9, 14, 18, 27, 31], [6, 8, 10, 19, 23, 25], [11, 12, 16, 20, 24, 34], [1, 5, 7, 13, 29, 37]], dtype=torch.float32).unsqueeze(0).to("cuda" if torch.cuda.is_available() else "cpu")
        h0 = torch.zeros(2, initial_sequence.size(0), 64).to("cuda" if torch.cuda.is_available() else "cpu")
        predicted_numbers = model(initial_sequence, h0)
        predicted_numbers = torch.round(predicted_numbers).type(torch.int)
        print("TRANSFORMER RNN:", predicted_numbers.cpu().numpy())
        return predicted_numbers.cpu().numpy()


# RNN 모델 학습 및 번호 예측
def train_rnn_model(epochs=50, batch_size=32):
    # 데이터 로더 준비
    dataset = LottoDataset()
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    # 모델 초기화
    device = "cuda" if torch.cuda.is_available() else "cpu"
    rnn_model = LOTTO_RNN().to(device)
    optimizer = Adam(rnn_model.parameters(), lr=1e-3)
    criterion = nn.MSELoss()

    # 모델 학습
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in loader:
            optimizer.zero_grad()
            inputs = inputs.float().to(device)
            targets = targets.float().to(device)
            h0 = torch.zeros(2, inputs.size(0), 64).to(device)
            outputs = rnn_model(inputs, h0)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(loader):.4f}")
    return rnn_model


# 모델 학습
rnn_model = train_rnn_model()

# 예측용 로또 번호 생성 예시 (예측에 적합한 이전 데이터 필요)
initial_sequence = torch.tensor([[3, 15, 21, 30, 33, 42], [4, 9, 14, 18, 27, 31], [6, 8, 10, 19, 23, 25], [11, 12, 16, 20, 24, 34], [1, 5, 7, 13, 29, 37]], dtype=torch.float32).unsqueeze(0).to("cuda" if torch.cuda.is_available() else "cpu")
h0 = torch.zeros(2, initial_sequence.size(0), 64).to("cuda" if torch.cuda.is_available() else "cpu")
predicted_numbers = rnn_model(initial_sequence, h0)
predicted_numbers = torch.round(predicted_numbers).type(torch.int)
print("TRANSFORMER RNN:", predicted_numbers.cpu().numpy())

RNN = predicted_numbers.cpu().numpy()
# torch.save(pca_model.state_dict(), '/content/drive/MyDrive/LOTTO_MODEL/model_PCA')
pickle.dump(rnn_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_RNN.pkl','wb'))

class LottoTransformer(nn.Module):
    def __init__(self, input_size=6, d_model=64, num_heads=8, num_layers=4, output_size=6):
        super(LottoTransformer, self).__init__()
        self.embedding = nn.Linear(input_size, d_model)
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.fc = nn.Linear(d_model, output_size)

    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        x = x[:, -1, :]  # Use only the last timestep's output for prediction
        return self.fc(x)

    def predict(self):
      # Prediction example
      initial_sequence = torch.tensor([[3, 15, 21, 30, 33, 42], [4, 9, 14, 18, 27, 31], [6, 8, 10, 19, 23, 25], [11, 12, 16, 20, 24, 34], [1, 5, 7, 13, 29, 37]], dtype=torch.float32).unsqueeze(0).to("cuda" if torch.cuda.is_available() else "cpu")
      predicted_numbers = trans_model(initial_sequence)
      predicted_numbers = torch.round(predicted_numbers).type(torch.int)
      print("Predicted Lotto Numbers:", predicted_numbers.cpu().numpy())
      return predicted_numbers.cpu().numpy()

def train_transformer_model(epochs=50, batch_size=32):
    dataset = LottoDataset()
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    trans_model = LottoTransformer().to(device)
    optimizer = Adam(trans_model.parameters(), lr=1e-3)
    criterion = nn.MSELoss()

    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in loader:
            optimizer.zero_grad()
            inputs, targets = inputs.float().to(device), targets.float().to(device)
            outputs = trans_model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(loader):.4f}")
    return trans_model

# Train the transformer model
trans_model = train_transformer_model()

# Prediction example
initial_sequence = torch.tensor([[3, 15, 21, 30, 33, 42], [4, 9, 14, 18, 27, 31], [6, 8, 10, 19, 23, 25], [11, 12, 16, 20, 24, 34], [1, 5, 7, 13, 29, 37]], dtype=torch.float32).unsqueeze(0).to("cuda" if torch.cuda.is_available() else "cpu")
predicted_numbers = trans_model(initial_sequence)
predicted_numbers = torch.round(predicted_numbers).type(torch.int)
print("Predicted Lotto Numbers:", predicted_numbers.cpu().numpy())

# Save the trained transformer model
pickle.dump(trans_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_TRANSFORMER.pkl', 'wb'))

"""# Linear"""

class LOTTO_linear(nn.Module):
    def __init__(self):
        super(LOTTO_linear, self).__init__()

        self.fc1 = nn.Linear(in_features=6, out_features=64)
        self.fc2 = nn.Linear(in_features=64, out_features=64)
        self.fc3 = nn.Linear(in_features=64, out_features=6)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x

    def predict(self):
      # 평균 손실 계산
      avg_loss = total_loss / len(loader)

      # 전체 손실 출력
      # print(f"Total Loss: {total_loss}")

      # 예시로 첫 번째 배치의 예측 값과 실제 값을 확인
      data, label = next(iter(loader))
      # print("LINEAR:", preds[0])
      # print("Example Ground Truth:", label.numpy())

      # 예측 값 반올림 및 정수형 변환
      final_preds = torch.round(pred).type(torch.int)
      # print("LINEAR:", final_preds.cpu().numpy())
      return preds[0]


# 학습
device = "cuda" if torch.cuda.is_available() else 'cpu'
lin_model = LOTTO_linear().to(device)
optim = Adam(lin_model.parameters(), lr=1e-4)

iterator = tqdm.tqdm(range(50))
for epoch in iterator:
    for data, label in loader:
        optim.zero_grad()
        # 모델 forward - 예측
        pred = lin_model(data.type(torch.FloatTensor).to(device))
        # 손실
        loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device).unsqueeze(1))
        # 역전파
        loss.backward()
        # 가중치 업데이트(최적화)
        optim.step()
        iterator.set_description(f"epoch{epoch+1} loss:{loss.item()}")
# 모델을 평가 모드로 설정
lin_model.eval()

# 평가 데이터셋을 이용하여 예측 수행 및 손실 계산
with torch.no_grad():
    for data, label in loader:
        # 모델에 데이터 전달하여 예측 수행
        pred = lin_model(data.type(torch.FloatTensor).to(device))

        # 예측 결과 및 손실 계산
        preds.append(pred.cpu().numpy())  # 예측값을 preds 리스트에 추가
        loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device).unsqueeze(1))
        total_loss += loss.item()

# 평균 손실 계산
avg_loss = total_loss / len(loader)

# 전체 손실 출력
print(f"Total Loss: {total_loss}")

# 예시로 첫 번째 배치의 예측 값과 실제 값을 확인
data, label = next(iter(loader))
print("LINEAR:", preds[0])
# print("Example Ground Truth:", label.numpy())

# 예측 값 반올림 및 정수형 변환
final_preds = torch.round(pred).type(torch.int)
# print("LINEAR:", final_preds.cpu().numpy())


pickle.dump(lin_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_LINEAR.pkl', 'wb'))

"""# RandomForestRegressor"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

class LOTTO_RANDOMFOREST:
    def __init__(self, max_depth=10, max_features='sqrt', min_samples_leaf=4, min_samples_split=2, n_estimators=300):
        self.rf_model = RandomForestRegressor(max_depth=max_depth, max_features=max_features,
                                              min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split,
                                              n_estimators=n_estimators)

    def fit(self, X, y, test_size=0.2, random_state=42):
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)

        # Reshape data for training
        X_train_2d = self.X_train.reshape(self.X_train.shape[0], -1)
        X_test_2d = self.X_test.reshape(self.X_test.shape[0], -1)

        # Train the model
        self.rf_model.fit(X_train_2d, self.y_train)

        # Evaluate the model
        self.accuracy = self.rf_model.score(X_test_2d, self.y_test)

    def predict(self):
        # Reshape test data for prediction
        X_test_2d = self.X_test.reshape(self.X_test.shape[0], -1)

        # Make predictions
        predictions = self.rf_model.predict(X_test_2d)
        predicted_numbers = np.round(predictions).astype(int)

        # Cap numbers to max lotto value (e.g., 45)
        predicted_numbers = np.where(predicted_numbers > 45, 45, predicted_numbers)

        return predicted_numbers[0]

# 사용 예시
X = np.random.rand(100, 6)  # 임의의 입력 데이터
y = np.random.randint(1, 46, size=(100, 6))  # 임의의 출력 데이터 (로또 번호)

rnf_model = LOTTO_RANDOMFOREST()
rnf_model.fit(X, y)
predicted_number = rnf_model.predict()

# print("RANDOM FOREST:", predicted_number)
# print("Model Accuracy:", lotto_model.accuracy)


pickle.dump(rnf_model, open('/content/drive/MyDrive/LOTTO_MODEL/model_RANDOMFOREST.pkl', 'wb'))

